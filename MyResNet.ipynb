{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mbaltac/anaconda/envs/dl_env/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation, BatchNormalization, \\\n",
    "    Input\n",
    "from keras.engine.topology import merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from image_util import crop_center\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "# from keras.utils.visualize_util import plot\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "Xtrain = np.load('./data/dataset256/Xtrain.npy')\n",
    "Xtest = np.load('./data/dataset256/Xtest.npy')\n",
    "Ytrain_reg = np.load('./data/dataset256/Ytrain_reg.npy')\n",
    "Ytest_reg = np.load('./data/dataset256/Ytest_reg.npy')\n",
    "Ytrain_cls = np.load('./data/dataset256/Ytrain_cls.npy')\n",
    "Ytest_cls = np.load('./data/dataset256/Ytest_cls.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (15405, 256, 256, 3)\n",
      "Xtest (3852, 256, 256, 3)\n",
      "Ytrain_reg (15405,)\n",
      "Ytest_reg (3852,)\n",
      "Ytrain_cls (15405,)\n",
      "Ytest_cls (3852,)\n"
     ]
    }
   ],
   "source": [
    "print ('Xtrain', Xtrain.shape)\n",
    "print ('Xtest', Xtest.shape)\n",
    "print ('Ytrain_reg', Ytrain_reg.shape)\n",
    "print ('Ytest_reg', Ytest_reg.shape)\n",
    "print ('Ytrain_cls', Ytrain_cls.shape)\n",
    "print ('Ytest_cls', Ytest_cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# netowrk settings\n",
    "\n",
    "batch_size = 64\n",
    "folder = './myresnet-training-checkpoint-new/'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "n_cls = int(np.max(Ytrain_cls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ytrain_cls = to_categorical(Ytrain_cls-1)\n",
    "Ytest_cls = to_categorical(Ytest_cls-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addResidualBlock(inp, size=(3,3), subsample=(4,4), filters_conv_rate=2, name=None):\n",
    "    conv_filters = int(inp.get_shape()[-1])*filters_conv_rate\n",
    "    inp = BatchNormalization()(inp)\n",
    "    first = Convolution2D(conv_filters, size[0], size[1], border_mode='same', subsample=subsample, activation='relu')(inp)\n",
    "    \n",
    "    second = BatchNormalization()(first)\n",
    "    second = Convolution2D(conv_filters, 3,3, border_mode='same', activation='relu')(second)\n",
    "    \n",
    "    second = BatchNormalization()(second)\n",
    "    second = Convolution2D(conv_filters, 3,3, border_mode='same', activation='relu')(second)\n",
    "    \n",
    "    return merge([first, second], mode='sum', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MyResNetRegr():\n",
    "    inp = Input(shape=(256, 256,3))\n",
    "    out = Convolution2D(16, 3,3, border_mode='same', activation='relu', subsample=(4,4))(inp)\n",
    "    for i in range(3):\n",
    "        out = addResidualBlock(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "    \n",
    "    out = BatchNormalization()(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(128, activation='relu', name='fcc')(out)\n",
    "    out = Dense(1, name='out')(out)\n",
    "    \n",
    "    model = Model(input=inp, output=out)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def MyResNetCls():\n",
    "    inp = Input(shape=(256, 256,3))\n",
    "    out = Convolution2D(16, 3,3, border_mode='same', activation='relu', subsample=(4,4))(inp)\n",
    "    for i in range(3):\n",
    "        out = addResidualBlock(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "    \n",
    "    out = BatchNormalization()(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(128, activation='relu', name='fcc')(out)\n",
    "    out = Dense(n_cls, activation='softmax', name='out')(out)\n",
    "    \n",
    "    model = Model(input=inp, output=out)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "def MyResNet2Obj():\n",
    "    inp = Input(shape=(256, 256,3))\n",
    "    out = Convolution2D(16, 3,3, border_mode='same', activation='relu', subsample=(4,4))(inp)\n",
    "    for i in range(3):\n",
    "        out = addResidualBlock(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "    \n",
    "    out = BatchNormalization()(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(128, activation='relu', name='fcc')(out)\n",
    "    out_reg = Dense(1, name='out_reg')(out)\n",
    "    out_cls = Dense(n_cls, activation='softmax', name='out_cls')(out)\n",
    "    \n",
    "    model = Model(input=inp, output=[out_reg, out_cls])\n",
    "    mr = Model(input=inp, output=out_reg)\n",
    "    mc = Model(input=inp, output=out_cls)\n",
    "\n",
    "    model.compile(loss=['mean_squared_error', 'categorical_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "    mr.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    mc.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model, mr, mc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_path = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load_path = './myresnet-training-checkpoint/reg_checkpoint/checkpoint-99-0.00.hdf5'\n",
    "if load_path:\n",
    "    model_reg = load_model(load_path)\n",
    "else:\n",
    "    model_reg = MyResNetRegr()\n",
    "# model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load_path = './myresnet-training-checkpoint/cls_checkpoint/checkpoint-99-0.39.hdf5'\n",
    "if load_path:\n",
    "    model_cls = load_model(load_path)\n",
    "else:\n",
    "    model_cls = MyResNetCls()\n",
    "# model_cls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load_path = './myresnet-training-checkpoint/2obj_checkpoint/checkpoint-99-1.55.hdf5'\n",
    "if load_path:\n",
    "    model = load_model(load_path)\n",
    "else:\n",
    "    model, mr, mc = MyResNet2Obj()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/2\n",
      "90/90 [==============================] - 1s - loss: 1.9922 - out_reg_loss: 0.2892 - out_cls_loss: 1.7030 - out_reg_acc: 0.0000e+00 - out_cls_acc: 0.4000 - val_loss: 37.8475 - val_out_reg_loss: 31.5371 - val_out_cls_loss: 6.3103 - val_out_reg_acc: 0.0000e+00 - val_out_cls_acc: 0.3000\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 1s - loss: 2.1073 - out_reg_loss: 0.5001 - out_cls_loss: 1.6073 - out_reg_acc: 0.0000e+00 - out_cls_acc: 0.3778 - val_loss: 15.0120 - val_out_reg_loss: 8.5387 - val_out_cls_loss: 6.4733 - val_out_reg_acc: 0.0000e+00 - val_out_cls_acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(folder + '2obj_checkpoint/'):\n",
    "    os.makedirs(folder + '2obj_checkpoint/')\n",
    "checkpoint = ModelCheckpoint(filepath=folder + '2obj_checkpoint/checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "history = model.fit(x=Xtrain[:100], y=[Ytrain_reg[:100], Ytrain_cls[:100]], \n",
    "          nb_epoch=2, batch_size=batch_size,validation_split=0.1, verbose=1, callbacks=[checkpoint]) \n",
    "mr.save(folder + '2obj_checkpoint/model_reg.hdf5')\n",
    "mc.save(folder + '2obj_checkpoint/model_cls.hdf5')\n",
    "with open(folder + '2obj_checkpoint/history.pkl', 'wb') as f:\n",
    "    pkl.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/2\n",
      "90/90 [==============================] - 7s - loss: 1.1124 - val_loss: 45.6573\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 1s - loss: 1.2440 - val_loss: 4.5591\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(folder + 'reg_checkpoint/'):\n",
    "    os.makedirs(folder + 'reg_checkpoint/')\n",
    "checkpoint = ModelCheckpoint(filepath=folder + '/reg_checkpoint/checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "history = model_reg.fit(x=Xtrain[:100], y=Ytrain_reg[:100], \n",
    "          nb_epoch=2, batch_size=batch_size,validation_split=0.1, verbose=1, callbacks=[checkpoint]) \n",
    "with open(folder + 'reg_checkpoint/history.pkl', 'wb') as f:\n",
    "    pkl.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/2\n",
      "90/90 [==============================] - 8s - loss: 2.2229 - val_loss: 4.0512\n",
      "Epoch 2/2\n",
      "90/90 [==============================] - 1s - loss: 1.6137 - val_loss: 4.4345\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(folder + 'cls_checkpoint/'):\n",
    "    os.makedirs(folder + 'cls_checkpoint/')\n",
    "checkpoint = ModelCheckpoint(filepath=folder + '/cls_checkpoint/checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "history = model_cls.fit(x=Xtrain[:100], y=Ytrain_cls[:100], \n",
    "          nb_epoch=2, batch_size=batch_size,validation_split=0.1, verbose=1, callbacks=[checkpoint]) \n",
    "with open(folder + 'cls_checkpoint/history.pkl', 'wb') as f:\n",
    "    pkl.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evl_both = model.evaluate(x=Xtest, y=[Ytest_reg, Ytest_cls],batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evl_cls = model_cls.evaluate(x=Xtest, y=Ytest_cls,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evl_reg = model_reg.evaluate(x=Xtest, y=Ytest_reg,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evl_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evl_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evl_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(folder + 'reg_checkpoint/history.pkl', 'rb') as f:\n",
    "    hitsory = pkl.load(f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.1123580733935039, 1.2439877324634128], 'val_loss': [45.657299041748047, 4.5590920448303223]}\n"
     ]
    }
   ],
   "source": [
    "print(hitsory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-404e70d89e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'reg_checkpoint/history.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhitsory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
