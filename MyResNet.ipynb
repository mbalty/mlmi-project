{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation, BatchNormalization, \\\n",
    "    Input\n",
    "from keras.engine.topology import merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from image_util import crop_center\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "Xtrain = np.load('./data/dataset256/Xtrain.npy')\n",
    "Xtest = np.load('./data/dataset256/Xtest.npy')\n",
    "Ytrain_reg = np.load('./data/dataset256/Ytrain_reg.npy')\n",
    "Ytest_reg = np.load('./data/dataset256/Ytest_reg.npy')\n",
    "Ytrain_cls = np.load('./data/dataset256/Ytrain_cls.npy')\n",
    "Ytest_cls = np.load('./data/dataset256/Ytest_cls.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (15405, 256, 256, 3)\n",
      "Xtest (3852, 256, 256, 3)\n",
      "Ytrain_reg (15405,)\n",
      "Ytest_reg (3852,)\n",
      "Ytrain_cls (15405,)\n",
      "Ytest_cls (3852,)\n"
     ]
    }
   ],
   "source": [
    "print ('Xtrain', Xtrain.shape)\n",
    "print ('Xtest', Xtest.shape)\n",
    "print ('Ytrain_reg', Ytrain_reg.shape)\n",
    "print ('Ytest_reg', Ytest_reg.shape)\n",
    "print ('Ytrain_cls', Ytrain_cls.shape)\n",
    "print ('Ytest_cls', Ytest_cls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# netowrk settings\n",
    "\n",
    "batch_size = 64\n",
    "nb_epoch = 2\n",
    "folder = './myresnet-cls-training-checkpoint/'\n",
    "load_path = False\n",
    "n_cls = int(np.max(Ytrain_cls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytrain_cls = to_categorical(Ytrain_cls-1)\n",
    "Ytest_cls = to_categorical(Ytest_cls-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addResidualBlock(inp, size=(3,3), subsample=(4,4), filters_conv_rate=2, name=None):\n",
    "    conv_filters = int(inp.get_shape()[-1])*filters_conv_rate\n",
    "    inp = BatchNormalization()(inp)\n",
    "    first = Convolution2D(conv_filters, size[0], size[1], border_mode='same', subsample=subsample, activation='relu')(inp)\n",
    "    \n",
    "    second = BatchNormalization()(first)\n",
    "    second = Convolution2D(conv_filters, 3,3, border_mode='same', activation='relu')(second)\n",
    "    \n",
    "    second = BatchNormalization()(second)\n",
    "    second = Convolution2D(conv_filters, 3,3, border_mode='same', activation='relu')(second)\n",
    "    \n",
    "    return merge([first, second], mode='sum', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MyResNetRegr():\n",
    "    inp = Input(shape=(256, 256,3))\n",
    "    out = Convolution2D(16, 3,3, border_mode='same', activation='relu', subsample=(4,4))(inp)\n",
    "    for i in range(3):\n",
    "        out = addResidualBlock(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "    \n",
    "    out = BatchNormalization()(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(128, activation='relu', name='fcc')(out)\n",
    "    out = Dense(1, name='out')(out)\n",
    "    \n",
    "    model = Model(input=inp, output=out)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def MyResNetCls():\n",
    "    inp = Input(shape=(256, 256,3))\n",
    "    out = Convolution2D(16, 3,3, border_mode='same', activation='relu', subsample=(4,4))(inp)\n",
    "    for i in range(3):\n",
    "        out = addResidualBlock(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "    \n",
    "    out = BatchNormalization()(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(128, activation='relu', name='fcc')(out)\n",
    "    out = Dense(n_cls, activation='softmax', name='out')(out)\n",
    "    \n",
    "    model = Model(input=inp, output=out)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "def MyResNet2Obj():\n",
    "    inp = Input(shape=(256, 256,3))\n",
    "    out = Convolution2D(16, 3,3, border_mode='same', activation='relu', subsample=(4,4))(inp)\n",
    "    for i in range(3):\n",
    "        out = addResidualBlock(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "    \n",
    "    out = BatchNormalization()(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(128, activation='relu', name='fcc')(out)\n",
    "    out_reg = Dense(1, name='out_reg')(out)\n",
    "    out_cls = Dense(n_cls, activation='softmax', name='out_cls')(out)\n",
    "    \n",
    "    model = Model(input=inp, output=[out_reg, out_cls])\n",
    "    model_reg = Model(input=inp, output=out_reg)\n",
    "    model_cls = Model(input=inp, output=out_cls)\n",
    "\n",
    "    model.compile(loss=['mean_squared_error', 'categorical_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "    model_reg.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_cls.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model, model_reg, model_cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if load_path:\n",
    "    model = load_model(load_path)\n",
    "else:\n",
    "    model = MyResNetRegr()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if load_path:\n",
    "    model = load_model(load_path)\n",
    "else:\n",
    "    model = MyResNetCls()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 256, 256, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 64, 16)    448         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 64, 64, 16)    64          convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 16, 16, 32)    4640        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 16, 16, 32)    128         convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 16, 16, 32)    9248        batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 16, 16, 32)    128         convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 16, 16, 32)    9248        batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 16, 16, 32)    0           convolution2d_2[0][0]            \n",
      "                                                                   convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 16, 16, 32)    128         merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 16, 32)    0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 16, 16, 32)    128         activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 4, 4, 64)      18496       batchnormalization_5[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_6 (BatchNorma (None, 4, 4, 64)      256         convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 4, 4, 64)      36928       batchnormalization_6[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_7 (BatchNorma (None, 4, 4, 64)      256         convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 4, 4, 64)      36928       batchnormalization_7[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 4, 4, 64)      0           convolution2d_5[0][0]            \n",
      "                                                                   convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_8 (BatchNorma (None, 4, 4, 64)      256         merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4, 4, 64)      0           batchnormalization_8[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_9 (BatchNorma (None, 4, 4, 64)      256         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 1, 1, 128)     73856       batchnormalization_9[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_10 (BatchNorm (None, 1, 1, 128)     512         convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 1, 1, 128)     147584      batchnormalization_10[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_11 (BatchNorm (None, 1, 1, 128)     512         convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 1, 1, 128)     147584      batchnormalization_11[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 1, 1, 128)     0           convolution2d_8[0][0]            \n",
      "                                                                   convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 1, 1, 128)     512         merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1, 1, 128)     0           batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNorm (None, 1, 1, 128)     512         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 128)           0           batchnormalization_13[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "fcc (Dense)                      (None, 128)           16512       flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "out_reg (Dense)                  (None, 1)             129         fcc[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "out_cls (Dense)                  (None, 7)             903         fcc[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 506,152\n",
      "Trainable params: 504,328\n",
      "Non-trainable params: 1,824\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if load_path:\n",
    "    model = load_model(load_path)\n",
    "else:\n",
    "    model, model_reg, model_cls = MyResNet2Obj()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch logger \n",
    "# ref: https://github.com/fchollet/keras/issues/2850#issuecomment-222542429\n",
    "class NBatchLogger(Callback):\n",
    "    def __init__(self,display=100):\n",
    "        '''\n",
    "        display: Number of batches to wait before outputting loss\n",
    "        '''\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "\n",
    "    def on_batch_end(self,batch,logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0:\n",
    "            print('\\n{0}/{1} - Batch Loss: {2}'.format(self.seen,self.params['nb_sample'],\n",
    "                                                self.params['metrics'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/2\n",
      "900/900 [==============================] - 15s - loss: 2.4099 - out_reg_loss: 0.4321 - out_cls_loss: 1.9778 - out_reg_acc: 0.0000e+00 - out_cls_acc: 0.2156 - val_loss: 11.7482 - val_out_reg_loss: 3.7271 - val_out_cls_loss: 8.0210 - val_out_reg_acc: 0.0000e+00 - val_out_cls_acc: 0.1000\n",
      "Epoch 2/2\n",
      "900/900 [==============================] - 9s - loss: 1.8553 - out_reg_loss: 0.2901 - out_cls_loss: 1.5652 - out_reg_acc: 0.0000e+00 - out_cls_acc: 0.4044 - val_loss: 12.3423 - val_out_reg_loss: 1.3051 - val_out_cls_loss: 11.0372 - val_out_reg_acc: 0.0000e+00 - val_out_cls_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "#train just 1000 samples, 3 epochs\n",
    "# if False:\n",
    "checkpoint = ModelCheckpoint(filepath=folder + 'checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "out_batch = NBatchLogger(display=1)\n",
    "history = model.fit(x=Xtrain[:1000], y=[Ytrain_reg[:1000], Ytrain_cls[:1000]], \n",
    "          nb_epoch=nb_epoch, batch_size=batch_size,validation_split=0.1, verbose=1, callbacks=[checkpoint]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_reg.save(folder + 'model_reg.hdf5')\n",
    "model_cls.save(folder + 'model_cls.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evl = model.evaluate(x=Xtest, y=Ytest,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation keras fix \n",
    "# ref: http://stackoverflow.com/questions/41796618/python-keras-cross-val-score-error/41841066#41841066\n",
    "from keras.wrappers.scikit_learn import BaseWrapper\n",
    "import copy\n",
    "\n",
    "def custom_get_params(self, **params):\n",
    "    res = copy.deepcopy(self.sk_params)\n",
    "    res.update({'build_fn': self.build_fn})\n",
    "    return res\n",
    "\n",
    "BaseWrapper.get_params = custom_get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regression \n",
    "# rev: http://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=MyNet, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, Xtrain[:1000], Ytrain[:1000], cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
