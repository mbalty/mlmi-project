{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation, BatchNormalization, \\\n",
    "    Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation keras fix \n",
    "# ref: http://stackoverflow.com/questions/41796618/python-keras-cross-val-score-error/41841066#41841066\n",
    "from keras.wrappers.scikit_learn import BaseWrapper\n",
    "import copy\n",
    "\n",
    "def custom_get_params(self, **params):\n",
    "    res = copy.deepcopy(self.sk_params)\n",
    "    res.update({'build_fn': self.build_fn})\n",
    "    return res\n",
    "\n",
    "BaseWrapper.get_params = custom_get_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "Xtrain = np.load('./data/dataset64/Xtrain.npy')\n",
    "Xtest = np.load('./data/dataset64/Xtest.npy')\n",
    "Ytrain = np.load('./data/dataset64/Ytrain.npy')\n",
    "Ytest = np.load('./data/dataset64/Ytest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# netowrk settings\n",
    "batch_size = 128\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MyNet():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(8, 5, 5, border_mode='same', input_shape=(64, 64,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(16, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Let's train the model using RMSprop\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 64, 8)     608         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 64, 64, 8)     0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 64, 64, 8)     32          activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 32, 8)     0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 30, 30, 16)    1168        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 30, 30, 16)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 30, 30, 16)    64          activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 15, 15, 16)    0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 15, 15, 32)    4640        maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 15, 15, 32)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 15, 15, 32)    128         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 7, 7, 32)      0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1568)          0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           803328      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 512)           2048        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           131328      batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 256)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 256)           1024        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             257         batchnormalization_5[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 944,625\n",
      "Trainable params: 942,977\n",
      "Non-trainable params: 1,648\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch logger \n",
    "# ref: https://github.com/fchollet/keras/issues/2850#issuecomment-222542429\n",
    "class NBatchLogger(Callback):\n",
    "    def __init__(self,display=100):\n",
    "        '''\n",
    "        display: Number of batches to wait before outputting loss\n",
    "        '''\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "\n",
    "    def on_batch_end(self,batch,logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0:\n",
    "            print('\\n{0}/{1} - Batch Loss: {2}'.format(self.seen,self.params['nb_sample'],\n",
    "                                                self.params['metrics'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "\n",
      "128/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 5s - loss: 0.2073\n",
      "256/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 4s - loss: 0.2817\n",
      "384/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 3s - loss: 0.3133\n",
      "512/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 2s - loss: 0.3273\n",
      "640/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 1s - loss: 0.3316\n",
      "768/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 0.3258\n",
      "896/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.3199\n",
      "900/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 6s - loss: 0.3215 - val_loss: 0.3120\n",
      "Epoch 2/5\n",
      "\n",
      "1028/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 5s - loss: 0.1997\n",
      "1156/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 4s - loss: 0.2391\n",
      "1284/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 3s - loss: 0.2228\n",
      "1412/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 2s - loss: 0.2375\n",
      "1540/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 1s - loss: 0.2328\n",
      "1668/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 0.2365\n",
      "1796/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.2938\n",
      "1800/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 6s - loss: 0.2954 - val_loss: 7.1993\n",
      "Epoch 3/5\n",
      "\n",
      "1928/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 5s - loss: 0.1813\n",
      "2056/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 4s - loss: 0.1734\n",
      "2184/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 3s - loss: 0.1907\n",
      "2312/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 2s - loss: 0.2007\n",
      "2440/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 1s - loss: 0.2076\n",
      "2568/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 0.2085\n",
      "2696/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.2116\n",
      "2700/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 6s - loss: 0.2122 - val_loss: 1.0936\n",
      "Epoch 4/5\n",
      "\n",
      "2828/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 5s - loss: 0.1417\n",
      "2956/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 4s - loss: 0.1588\n",
      "3084/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 3s - loss: 0.1812\n",
      "3212/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 2s - loss: 0.2012\n",
      "3340/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 1s - loss: 0.2116\n",
      "3468/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 0.2052\n",
      "3596/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.1933\n",
      "3600/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 6s - loss: 0.1929 - val_loss: 0.4171\n",
      "Epoch 5/5\n",
      "\n",
      "3728/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 5s - loss: 0.1865\n",
      "3856/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 4s - loss: 0.1745\n",
      "3984/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 3s - loss: 0.1763\n",
      "4112/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 2s - loss: 0.1715\n",
      "4240/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 2s - loss: 0.1586\n",
      "4368/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 1s - loss: 0.1713\n",
      "4496/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.1630\n",
      "4500/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 7s - loss: 0.1629 - val_loss: 0.3611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b066240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train just 1000 samples, 3 epochs\n",
    "# if False:\n",
    "checkpoint = ModelCheckpoint(filepath='./training-checkpoint/checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "out_batch = NBatchLogger(display=1)\n",
    "model.fit(x=Xtrain[:1000], y=Ytrain[:1000], \n",
    "          nb_epoch=nb_epoch, batch_size=batch_size,validation_split=0.1, verbose=1, callbacks=[checkpoint, out_batch]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852/3852 [==============================] - 9s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25278521642506679"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=Xtest, y=Ytest,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regression \n",
    "# rev: http://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=MyNet, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "900/900 [==============================] - 7s - loss: 2.2799     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.4239     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.7362     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 6s - loss: 0.5345     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.4138     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 8s - loss: 1.7907     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 3.7076     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.6714     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.3546     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.2271     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 8s - loss: 1.9293     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.5638     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.6591     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 6s - loss: 0.2976     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.3312     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 8s - loss: 1.7527     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.2445     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.4404     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 6s - loss: 0.2888     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.2041     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.0120     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 2.7611     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 1.6787     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.6011     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.4096     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.2168     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 8s - loss: 1.4634     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.7140     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.5918     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.3331     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.1819     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.2458     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.5759     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.2275     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.1684     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 10s - loss: 3.5544    \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 1.0074     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.5541     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.4046     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.2918     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.1261     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 1.5947     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.6275     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.3308     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.2131     \n",
      "100/100 [==============================] - 1s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 10s - loss: 2.0462    \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 1.9618     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 1.2253     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 8s - loss: 0.8854     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.3961     \n",
      "100/100 [==============================] - 1s\n",
      "Results: 2.92 (4.41) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, Xtrain[:1000], Ytrain[:1000], cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
