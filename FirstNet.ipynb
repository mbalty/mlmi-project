{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation, BatchNormalization, \\\n",
    "    Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation keras fix \n",
    "# ref: http://stackoverflow.com/questions/41796618/python-keras-cross-val-score-error/41841066#41841066\n",
    "from keras.wrappers.scikit_learn import BaseWrapper\n",
    "import copy\n",
    "\n",
    "def custom_get_params(self, **params):\n",
    "    res = copy.deepcopy(self.sk_params)\n",
    "    res.update({'build_fn': self.build_fn})\n",
    "    return res\n",
    "\n",
    "BaseWrapper.get_params = custom_get_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "Xtrain = np.load('./data/dataset64/Xtrain.npy')\n",
    "Xtest = np.load('./data/dataset64/Xtest.npy')\n",
    "Ytrain = np.load('./data/dataset64/Ytrain.npy')\n",
    "Ytest = np.load('./data/dataset64/Ytest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# netowrk settings\n",
    "batch_size = 128\n",
    "nb_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MyNet():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(8, 5, 5, border_mode='same', input_shape=(64, 64,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(16, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 64, 8)     608         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 64, 64, 8)     0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_1 (BatchNorma (None, 64, 64, 8)     32          activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 32, 8)     0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 30, 30, 16)    1168        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 30, 30, 16)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 30, 30, 16)    64          activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 15, 15, 16)    0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 15, 15, 32)    4640        maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 15, 15, 32)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 15, 15, 32)    128         activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 7, 7, 32)      0           batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1568)          0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           803328      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 512)           2048        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           131328      batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 256)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 256)           1024        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             257         batchnormalization_5[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 944,625\n",
      "Trainable params: 942,977\n",
      "Non-trainable params: 1,648\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch logger \n",
    "# ref: https://github.com/fchollet/keras/issues/2850#issuecomment-222542429\n",
    "class NBatchLogger(Callback):\n",
    "    def __init__(self,display=100):\n",
    "        '''\n",
    "        display: Number of batches to wait before outputting loss\n",
    "        '''\n",
    "        self.seen = 0\n",
    "        self.display = display\n",
    "\n",
    "    def on_batch_end(self,batch,logs={}):\n",
    "        self.seen += logs.get('size', 0)\n",
    "        if self.seen % self.display == 0:\n",
    "            print('\\n{0}/{1} - Batch Loss: {2}'.format(self.seen,self.params['nb_sample'],\n",
    "                                                self.params['metrics'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "\n",
      "128/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 17s - loss: 2.1667\n",
      "256/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 9s - loss: 4.0477 \n",
      "384/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 6s - loss: 3.2048\n",
      "512/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 4s - loss: 3.0973\n",
      "640/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 2s - loss: 2.8785\n",
      "768/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 1s - loss: 2.6843\n",
      "896/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 2.5290\n",
      "900/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 10s - loss: 2.5205 - val_loss: 0.6075\n",
      "Epoch 2/5\n",
      "\n",
      "1028/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 5s - loss: 4.3158\n",
      "1156/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 4s - loss: 2.6927\n",
      "1284/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 3s - loss: 3.3603\n",
      "1412/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 2s - loss: 2.8193\n",
      "1540/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 1s - loss: 2.5810\n",
      "1668/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 2.3006\n",
      "1796/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 2.0814\n",
      "1800/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 6s - loss: 2.0762 - val_loss: 0.9619\n",
      "Epoch 3/5\n",
      "\n",
      "1928/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 5s - loss: 0.4956\n",
      "2056/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 4s - loss: 0.4720\n",
      "2184/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 3s - loss: 0.5677\n",
      "2312/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 2s - loss: 0.5364\n",
      "2440/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 1s - loss: 0.6429\n",
      "2568/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 0.6579\n",
      "2696/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.6985\n",
      "2700/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 6s - loss: 0.6962 - val_loss: 5.8157\n",
      "Epoch 4/5\n",
      "\n",
      "2828/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 6s - loss: 0.6285\n",
      "2956/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 5s - loss: 0.6183\n",
      "3084/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 4s - loss: 0.5427\n",
      "3212/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 3s - loss: 0.5238\n",
      "3340/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 2s - loss: 0.5994\n",
      "3468/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 0.6762\n",
      "3596/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.6688\n",
      "3600/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 7s - loss: 0.6684 - val_loss: 1.4286\n",
      "Epoch 5/5\n",
      "\n",
      "3728/900 - Batch Loss: loss\n",
      "128/900 [===>..........................] - ETA: 6s - loss: 0.1766\n",
      "3856/900 - Batch Loss: loss\n",
      "256/900 [=======>......................] - ETA: 5s - loss: 0.2273\n",
      "3984/900 - Batch Loss: loss\n",
      "384/900 [===========>..................] - ETA: 4s - loss: 0.2433\n",
      "4112/900 - Batch Loss: loss\n",
      "512/900 [================>.............] - ETA: 3s - loss: 0.2564\n",
      "4240/900 - Batch Loss: loss\n",
      "640/900 [====================>.........] - ETA: 1s - loss: 0.2704\n",
      "4368/900 - Batch Loss: loss\n",
      "768/900 [========================>.....] - ETA: 0s - loss: 0.2670\n",
      "4496/900 - Batch Loss: loss\n",
      "896/900 [============================>.] - ETA: 0s - loss: 0.2650\n",
      "4500/900 - Batch Loss: loss\n",
      "900/900 [==============================] - 7s - loss: 0.2698 - val_loss: 0.9149\n"
     ]
    }
   ],
   "source": [
    "#train just 1000 samples, 3 epochs\n",
    "# if False:\n",
    "checkpoint = ModelCheckpoint(filepath='./training-checkpoint/checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "out_batch = NBatchLogger(display=1)\n",
    "history = model.fit(x=Xtrain[:1000], y=Ytrain[:1000], \n",
    "          nb_epoch=nb_epoch, batch_size=batch_size,validation_split=0.1, verbose=1, callbacks=[checkpoint, out_batch]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15645ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852/3852 [==============================] - 9s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.87027442789523402"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=Xtest, y=Ytest,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regression \n",
    "# rev: http://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=MyNet, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "900/900 [==============================] - 7s - loss: 2.2799     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.4239     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.7362     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 6s - loss: 0.5345     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.4138     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 8s - loss: 1.7907     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 3.7076     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.6714     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.3546     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.2271     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 8s - loss: 1.9293     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.5638     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.6591     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 6s - loss: 0.2976     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.3312     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 8s - loss: 1.7527     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.2445     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 6s - loss: 0.4404     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 6s - loss: 0.2888     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 6s - loss: 0.2041     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.0120     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 2.7611     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 1.6787     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.6011     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.4096     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.2168     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 8s - loss: 1.4634     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.7140     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.5918     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.3331     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.1819     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 6s - loss: 1.2458     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.5759     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.2275     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.1684     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 10s - loss: 3.5544    \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 1.0074     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.5541     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.4046     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.2918     \n",
      "100/100 [==============================] - 0s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 9s - loss: 2.1261     \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 1.5947     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 0.6275     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 7s - loss: 0.3308     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.2131     \n",
      "100/100 [==============================] - 1s\n",
      "Epoch 1/5\n",
      "900/900 [==============================] - 10s - loss: 2.0462    \n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 7s - loss: 1.9618     \n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 7s - loss: 1.2253     \n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 8s - loss: 0.8854     \n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 7s - loss: 0.3961     \n",
      "100/100 [==============================] - 1s\n",
      "Results: 2.92 (4.41) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, Xtrain[:1000], Ytrain[:1000], cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
